{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プロセス  \n",
    "分かち書き  \n",
    "形態素解析  \n",
    "機能表現  \n",
    "構文解析  \n",
    "格文法導入  \n",
    "述語項構造導入  \n",
    "対応解析  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分析タスク  \n",
    "クラスタリングとかで、同じような言葉をまとめる  \n",
    "分類、落とし込む先が決まっている、教師あり学習  \n",
    "生成タスク  \n",
    "ようやく分生成(単語重みづけ)  \n",
    "対話システム  \n",
    "機械翻訳  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAG OF WORDS  \n",
    "文章‐単語行列  \n",
    "BAG OF WORDS の応用  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSI？潜在意味解析\n",
    " 　　特異値分解、次元圧縮、トピックは直行するように、文章や単語の分布はガウス分布行列要素は負の値だったら解釈できない  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLSI  \n",
    "LSIの確立生起モデル  \n",
    "\n",
    "数式はいろいろ、後程消化　 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まとめとして、  \n",
    "単語はトピックによって生起される  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HHM  \n",
    "　文章を考える  \n",
    "　単語Xt にはラベルYtが存在  \n",
    "　ラベルYtはラベルYt-1Aの影響を受ける  \n",
    " D={(x1,y1)(x2,y2)....(xn,yn)}\n",
    " 　で、Dを訓練  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "服装データでやってみます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mecab text_fashion.txt > mecab_output.txt\n",
    "#テキストファイルをメカブファイルにします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1行ずつ読み込み、名詞の集合（話題）を取得する（演習問題）\n",
    "# strip()の引数を省略すると空白だけでなく改行も除去される\n",
    "# mecab の品詞体系は以下のサイトに記載されています\n",
    "# http://www.unixuser.org/~euske/doc/postag/#chasen\n",
    "f = open('mecab_output.txt', 'r',encoding='UTF-8')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "out = {}\n",
    "for line in lines:\n",
    "    line = line.strip() # 超重要\n",
    "\n",
    "    # EOSを避けるためにtry-except構文を利用\n",
    "    try:\n",
    "        surf = line.split(\"\\t\")[0] #表層系を取得\n",
    "        base = line.split(\"\\t\")[1].split(',')[6] # 基本形\n",
    "        pos0 = line.split(\"\\t\")[1].split(',')[0] # 品詞\n",
    "        pos1 = line.split(\"\\t\")[1].split(',')[1] # 品詞細分類1\n",
    "        \n",
    "        # 品詞細分類が一般・固有名詞の名詞を抽出\n",
    "        if (pos0 == '名詞') and (pos1 in ['一般', '固有名詞']):\n",
    "            # base=* 基本形が判定できないもの(未知語など) → 表層系を取得 ex) タクシー乗る　タクる\n",
    "            if base == '*':\n",
    "                word = surf\n",
    "            else:\n",
    "                word = base\n",
    "            if word in out:\n",
    "                out[word] += 1\n",
    "            else:\n",
    "                out[word] = 1\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "out = sorted(out.items(), key=lambda x: x[1], reverse = True)\n",
    "\n",
    "f = open('noun_list.csv', 'w', encoding = 'UTF-8')\n",
    "f.write('word,count\\n')\n",
    "\n",
    "cnt = 1\n",
    "for taple in out:\n",
    "    print(taple)\n",
    "    word, count = taple\n",
    "    f.write(word + ',' + str(count) + \"\\n\")\n",
    "    cnt += 1\n",
    "    if cnt > 100:\n",
    "        break\n",
    "f.close()\n",
    "\n",
    "#通販のサイトなので、製品。サイズなどが話題になる(注目されている)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    surf = line.split(\"\\t\")[0] #表層系を取得\n",
    "    base = line.split(\"\\t\")[1].split(',')[6] # 基本形\n",
    "    pos0 = line.split(\"\\t\")[1].split(',')[0] # 品詞\n",
    "    pos1 = line.split(\"\\t\")[1].split(',')[1] # 品詞細分類1\n",
    "    \n",
    "    if(pos0 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
