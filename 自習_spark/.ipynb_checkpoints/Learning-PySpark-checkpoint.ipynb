{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkConf,SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf().setMaster('local').setAppName('My App')\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize(\n",
    " [('Amber', 22), ('Alfred', 23), ('Skye',4), ('Albert', 12),\n",
    " ('Amber', 9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_heterogenous = sc.parallelize([\n",
    " ('Ferrari', 'fast'),\n",
    " {'Porsche': 100000},\n",
    " ['Spain','visited', 4504]\n",
    "]).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_file = sc.textFile(r'C:\\Users\\ko_kaku\\Desktop\\self_learning\\spark\\houseprice_data\\train.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rddを作る際に、直接作るか、あるいは、データの読み込みも可能です"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered = data_from_file.filter(lambda row: row[5] == 'F' and row[21] == '0')\n",
    "data_filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputRDD = sc.textFile(\"./houseprice_data/train.csv\")\n",
    "errorsRDD = inputRDD.filter(lambda x: \"error\" in x)\n",
    "warningsRDD = inputRDD.filter(lambda x: \"warning\" in x)\n",
    "badLinesRDD = errorsRDD.union(warningsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id,MSSubClass,MSZoning,LotFrontage,LotArea,Street,Alley,LotShape,LandContour,Utilities,LotConfig,LandSlope,Neighborhood,Condition1,Condition2,BldgType,HouseStyle,OverallQual,OverallCond,YearBuilt,YearRemodAdd,RoofStyle,RoofMatl,Exterior1st,Exterior2nd,MasVnrType,MasVnrArea,ExterQual,ExterCond,Foundation,BsmtQual,BsmtCond,BsmtExposure,BsmtFinType1,BsmtFinSF1,BsmtFinType2,BsmtFinSF2,BsmtUnfSF,TotalBsmtSF,Heating,HeatingQC,CentralAir,Electrical,1stFlrSF,2ndFlrSF,LowQualFinSF,GrLivArea,BsmtFullBath,BsmtHalfBath,FullBath,HalfBath,BedroomAbvGr,KitchenAbvGr,KitchenQual,TotRmsAbvGrd,Functional,Fireplaces,FireplaceQu,GarageType,GarageYrBlt,GarageFinish,GarageCars,GarageArea,GarageQual,GarageCond,PavedDrive,WoodDeckSF,OpenPorchSF,EnclosedPorch,3SsnPorch,ScreenPorch,PoolArea,PoolQC,Fence,MiscFeature,MiscVal,MoSold,YrSold,SaleType,SaleCondition,SalePrice']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_from_file.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d', ',', ',', ',', ',', ',', ',', ',', ',', ',']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_from_file.map(lambda row: row[1]).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id,MSSubClass,MSZoning,LotFrontage,LotArea,Street,Alley,LotShape,LandContour,Utilities,LotConfig,LandSlope,Neighborhood,Condition1,Condition2,BldgType,HouseStyle,OverallQual,OverallCond,YearBuilt,YearRemodAdd,RoofStyle,RoofMatl,Exterior1st,Exterior2nd,MasVnrType,MasVnrArea,ExterQual,ExterCond,Foundation,BsmtQual,BsmtCond,BsmtExposure,BsmtFinType1,BsmtFinSF1,BsmtFinType2,BsmtFinSF2,BsmtUnfSF,TotalBsmtSF,Heating,HeatingQC,CentralAir,Electrical,1stFlrSF,2ndFlrSF,LowQualFinSF,GrLivArea,BsmtFullBath,BsmtHalfBath,FullBath,HalfBath,BedroomAbvGr,KitchenAbvGr,KitchenQual,TotRmsAbvGrd,Functional,Fireplaces,FireplaceQu,GarageType,GarageYrBlt,GarageFinish,GarageCars,GarageArea,GarageQual,GarageCond,PavedDrive,WoodDeckSF,OpenPorchSF,EnclosedPorch,3SsnPorch,ScreenPorch,PoolArea,PoolQC,Fence,MiscFeature,MiscVal,MoSold,YrSold,SaleType,SaleCondition,SalePrice']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_from_file.filter(lambda row: row[1] =='d').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S', 'R', '0', ',', '6', '2', '9', '5', '8', '3', '1', '7', '4']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_distinct = data_from_file.map(lambda row: row[5]).distinct().collect()\n",
    "distinct_distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', (4, '6')), ('c', (10, None)), ('a', (1, 4)), ('a', (1, 1))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([('a', 1), ('b', 4), ('c',10)])\n",
    "rdd2 = sc.parallelize([('a', 4), ('a', 1), ('b', '6'), ('d', 15)])\n",
    "rdd1.leftOuterJoin(rdd2).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.map(lambda row: row[1]).reduce(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reduce = sc.parallelize([1, 2, .5, .1, 5, .2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "works = data_reduce.reduce(lambda x, y: x / y)\n",
    "works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reduce = sc.parallelize([1, 2, .5, .1, 5, .2], 3)\n",
    "data_reduce.reduce(lambda x, y: x / y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 4), ('c', 2), ('a', 12), ('d', 5)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_key = sc.parallelize([('a', 4),('b', 3),('c', 2),('a', 8),('d', 2),('b', 1),('d', 3)],4)\n",
    "data_key.reduceByKey(lambda x, y: x + y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringJSONRDD = sc.parallelize((\"\"\" \n",
    "  { \"id\": \"123\",\n",
    "    \"name\": \"Katie\",\n",
    "    \"age\": 19,\n",
    "    \"eyeColor\": \"brown\"\n",
    "  }\"\"\",\n",
    "   \"\"\"{\n",
    "    \"id\": \"234\",\n",
    "    \"name\": \"Michael\",\n",
    "    \"age\": 22,\n",
    "    \"eyeColor\": \"green\"\n",
    "  }\"\"\", \n",
    "  \"\"\"{\n",
    "    \"id\": \"345\",\n",
    "    \"name\": \"Simone\",\n",
    "    \"age\": 23,\n",
    "    \"eyeColor\": \"blue\"\n",
    "  }\"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' \\n  { \"id\": \"123\",\\n    \"name\": \"Katie\",\\n    \"age\": 19,\\n    \"eyeColor\": \"brown\"\\n  }',\n",
       " '{\\n    \"id\": \"234\",\\n    \"name\": \"Michael\",\\n    \"age\": 22,\\n    \"eyeColor\": \"green\"\\n  }',\n",
       " '{\\n    \"id\": \"345\",\\n    \"name\": \"Simone\",\\n    \"age\": 23,\\n    \"eyeColor\": \"blue\"\\n  }']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringJSONRDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "swimmersJSON = spark.read.json(stringJSONRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "swimmersJSON.createOrReplaceTempView('swimmersJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+-------+\n",
      "|age|eyeColor| id|   name|\n",
      "+---+--------+---+-------+\n",
      "| 19|   brown|123|  Katie|\n",
      "| 22|   green|234|Michael|\n",
      "| 23|    blue|345| Simone|\n",
      "+---+--------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swimmersJSON.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=19, eyeColor='brown', id='123', name='Katie'),\n",
       " Row(age=22, eyeColor='green', id='234', name='Michael'),\n",
       " Row(age=23, eyeColor='blue', id='345', name='Simone')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SQL Query\n",
    "spark.sql(\"select * from swimmersJSON\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- eyeColor: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swimmersJSON.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欠損値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_miss = spark.createDataFrame([\n",
    "        (1, 143.5, 5.6, 28,   'M',  100000),\n",
    "        (2, 167.2, 5.4, 45,   'M',  None),\n",
    "        (3, None , 5.2, None, None, None),\n",
    "        (4, 144.5, 5.9, 33,   'M',  None),\n",
    "        (5, 133.2, 5.7, 54,   'F',  None),\n",
    "        (6, 124.1, 5.2, None, 'F',  None),\n",
    "        (7, 129.2, 5.3, 42,   'M',  76000),\n",
    "    ], ['id', 'weight', 'height', 'age', 'gender', 'income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+------+\n",
      "| id|weight|height| age|gender|income|\n",
      "+---+------+------+----+------+------+\n",
      "|  3|  null|   5.2|null|  null|  null|\n",
      "+---+------+------+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_miss.where('id == 3').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+------+\n",
      "| id|weight|height| age|gender|income|\n",
      "+---+------+------+----+------+------+\n",
      "|  1| 143.5|   5.6|  28|     M|100000|\n",
      "|  2| 167.2|   5.4|  45|     M|  null|\n",
      "|  4| 144.5|   5.9|  33|     M|  null|\n",
      "|  5| 133.2|   5.7|  54|     F|  null|\n",
      "|  6| 124.1|   5.2|null|     F|  null|\n",
      "|  7| 129.2|   5.3|  42|     M| 76000|\n",
      "+---+------+------+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_miss.dropna(thresh=3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欠損値補間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+------+---+-------+------+\n",
      "| id|            weight|height|age| gender|income|\n",
      "+---+------------------+------+---+-------+------+\n",
      "|  1|             143.5|   5.6| 28|      M|100000|\n",
      "|  2|             167.2|   5.4| 45|      M| 88000|\n",
      "|  3|140.28333333333333|   5.2| 40|missing| 88000|\n",
      "|  4|             144.5|   5.9| 33|      M| 88000|\n",
      "|  5|             133.2|   5.7| 54|      F| 88000|\n",
      "|  6|             124.1|   5.2| 40|      F| 88000|\n",
      "|  7|             129.2|   5.3| 42|      M| 76000|\n",
      "+---+------------------+------+---+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "means = df_miss.agg(\n",
    "    *[fn.mean(c).alias(c) for c in df_miss.columns if c != 'gender']\n",
    ").toPandas().to_dict('records')[0]\n",
    "means\n",
    "means['gender'] = 'missing'\n",
    "\n",
    "df_miss.fillna(means).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers = spark.createDataFrame([\n",
    "        (1, 143.5, 5.3, 28),\n",
    "        (2, 154.2, 5.5, 45),\n",
    "        (3, 342.3, 5.1, 99),\n",
    "        (4, 144.5, 5.5, 33),\n",
    "        (5, 133.2, 5.4, 54),\n",
    "        (6, 124.1, 5.1, 21),\n",
    "        (7, 129.2, 5.3, 42),\n",
    "    ], ['id', 'weight', 'height', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['weight', 'height', 'age']\n",
    "bounds = {}\n",
    "\n",
    "for col in cols:\n",
    "    quantiles = df_outliers.approxQuantile(col, [0.25, 0.75], 0.05)\n",
    "    IQR = quantiles[1] - quantiles[0]\n",
    "    bounds[col] = [quantiles[0] - 1.5 * IQR, quantiles[1] + 1.5 * IQR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------+-----+\n",
      "| id|weight_o|height_o|age_o|\n",
      "+---+--------+--------+-----+\n",
      "|  1|   false|   false|false|\n",
      "|  2|   false|   false|false|\n",
      "|  3|    true|   false| true|\n",
      "|  4|   false|   false|false|\n",
      "|  5|   false|   false|false|\n",
      "|  6|   false|   false|false|\n",
      "|  7|   false|   false|false|\n",
      "+---+--------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outliers = df_outliers.select(*['id'] + [\n",
    "    (\n",
    "        (df_outliers[c] < bounds[c][0]) | \n",
    "        (df_outliers[c] > bounds[c][1])\n",
    "    ).alias(c + '_o') for c in cols\n",
    "])\n",
    "outliers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|weight|\n",
      "+---+------+\n",
      "|  3| 342.3|\n",
      "+---+------+\n",
      "\n",
      "+---+---+\n",
      "| id|age|\n",
      "+---+---+\n",
      "|  3| 99|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers = df_outliers.join(outliers, on='id')\n",
    "df_outliers.filter('weight_o').select('id', 'weight').show()\n",
    "df_outliers.filter('age_o').select('id', 'age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyspark and ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as typ\n",
    "\n",
    "labels = [\n",
    "    ('INFANT_ALIVE_AT_REPORT', typ.StringType()),\n",
    "    ('BIRTH_YEAR', typ.IntegerType()),\n",
    "    ('BIRTH_MONTH', typ.IntegerType()),\n",
    "    ('BIRTH_PLACE', typ.StringType()),\n",
    "    ('MOTHER_AGE_YEARS', typ.IntegerType()),\n",
    "    ('MOTHER_RACE_6CODE', typ.StringType()),\n",
    "    ('MOTHER_EDUCATION', typ.StringType()),\n",
    "    ('FATHER_COMBINED_AGE', typ.IntegerType()),\n",
    "    ('FATHER_EDUCATION', typ.StringType()),\n",
    "    ('MONTH_PRECARE_RECODE', typ.StringType()),\n",
    "    ('CIG_BEFORE', typ.IntegerType()),\n",
    "    ('CIG_1_TRI', typ.IntegerType()),\n",
    "    ('CIG_2_TRI', typ.IntegerType()),\n",
    "    ('CIG_3_TRI', typ.IntegerType()),\n",
    "    ('MOTHER_HEIGHT_IN', typ.IntegerType()),\n",
    "    ('MOTHER_BMI_RECODE', typ.IntegerType()),\n",
    "    ('MOTHER_PRE_WEIGHT', typ.IntegerType()),\n",
    "    ('MOTHER_DELIVERY_WEIGHT', typ.IntegerType()),\n",
    "    ('MOTHER_WEIGHT_GAIN', typ.IntegerType()),\n",
    "    ('DIABETES_PRE', typ.StringType()),\n",
    "    ('DIABETES_GEST', typ.StringType()),\n",
    "    ('HYP_TENS_PRE', typ.StringType()),\n",
    "    ('HYP_TENS_GEST', typ.StringType()),\n",
    "    ('PREV_BIRTH_PRETERM', typ.StringType()),\n",
    "    ('NO_RISK', typ.StringType()),\n",
    "    ('NO_INFECTIONS_REPORTED', typ.StringType()),\n",
    "    ('LABOR_IND', typ.StringType()),\n",
    "    ('LABOR_AUGM', typ.StringType()),\n",
    "    ('STEROIDS', typ.StringType()),\n",
    "    ('ANTIBIOTICS', typ.StringType()),\n",
    "    ('ANESTHESIA', typ.StringType()),\n",
    "    ('DELIV_METHOD_RECODE_COMB', typ.StringType()),\n",
    "    ('ATTENDANT_BIRTH', typ.StringType()),\n",
    "    ('APGAR_5', typ.IntegerType()),\n",
    "    ('APGAR_5_RECODE', typ.StringType()),\n",
    "    ('APGAR_10', typ.IntegerType()),\n",
    "    ('APGAR_10_RECODE', typ.StringType()),\n",
    "    ('INFANT_SEX', typ.StringType()),\n",
    "    ('OBSTETRIC_GESTATION_WEEKS', typ.IntegerType()),\n",
    "    ('INFANT_WEIGHT_GRAMS', typ.IntegerType()),\n",
    "    ('INFANT_ASSIST_VENTI', typ.StringType()),\n",
    "    ('INFANT_ASSIST_VENTI_6HRS', typ.StringType()),\n",
    "    ('INFANT_NICU_ADMISSION', typ.StringType()),\n",
    "    ('INFANT_SURFACANT', typ.StringType()),\n",
    "    ('INFANT_ANTIBIOTICS', typ.StringType()),\n",
    "    ('INFANT_SEIZURES', typ.StringType()),\n",
    "    ('INFANT_NO_ABNORMALITIES', typ.StringType()),\n",
    "    ('INFANT_ANCEPHALY', typ.StringType()),\n",
    "    ('INFANT_MENINGOMYELOCELE', typ.StringType()),\n",
    "    ('INFANT_LIMB_REDUCTION', typ.StringType()),\n",
    "    ('INFANT_DOWN_SYNDROME', typ.StringType()),\n",
    "    ('INFANT_SUSPECTED_CHROMOSOMAL_DISORDER', typ.StringType()),\n",
    "    ('INFANT_NO_CONGENITAL_ANOMALIES_CHECKED', typ.StringType()),\n",
    "    ('INFANT_BREASTFED', typ.StringType())\n",
    "]\n",
    "\n",
    "schema = typ.StructType([\n",
    "        typ.StructField(e[0], e[1], False) for e in labels\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "births = spark.read.csv('./data_learning_pyspark/births_train.csv.gz', \n",
    "                        header=True, \n",
    "                        schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- INFANT_ALIVE_AT_REPORT: string (nullable = true)\n",
      " |-- BIRTH_YEAR: integer (nullable = true)\n",
      " |-- BIRTH_MONTH: integer (nullable = true)\n",
      " |-- BIRTH_PLACE: string (nullable = true)\n",
      " |-- MOTHER_AGE_YEARS: integer (nullable = true)\n",
      " |-- MOTHER_RACE_6CODE: string (nullable = true)\n",
      " |-- MOTHER_EDUCATION: string (nullable = true)\n",
      " |-- FATHER_COMBINED_AGE: integer (nullable = true)\n",
      " |-- FATHER_EDUCATION: string (nullable = true)\n",
      " |-- MONTH_PRECARE_RECODE: string (nullable = true)\n",
      " |-- CIG_BEFORE: integer (nullable = true)\n",
      " |-- CIG_1_TRI: integer (nullable = true)\n",
      " |-- CIG_2_TRI: integer (nullable = true)\n",
      " |-- CIG_3_TRI: integer (nullable = true)\n",
      " |-- MOTHER_HEIGHT_IN: integer (nullable = true)\n",
      " |-- MOTHER_BMI_RECODE: integer (nullable = true)\n",
      " |-- MOTHER_PRE_WEIGHT: integer (nullable = true)\n",
      " |-- MOTHER_DELIVERY_WEIGHT: integer (nullable = true)\n",
      " |-- MOTHER_WEIGHT_GAIN: integer (nullable = true)\n",
      " |-- DIABETES_PRE: string (nullable = true)\n",
      " |-- DIABETES_GEST: string (nullable = true)\n",
      " |-- HYP_TENS_PRE: string (nullable = true)\n",
      " |-- HYP_TENS_GEST: string (nullable = true)\n",
      " |-- PREV_BIRTH_PRETERM: string (nullable = true)\n",
      " |-- NO_RISK: string (nullable = true)\n",
      " |-- NO_INFECTIONS_REPORTED: string (nullable = true)\n",
      " |-- LABOR_IND: string (nullable = true)\n",
      " |-- LABOR_AUGM: string (nullable = true)\n",
      " |-- STEROIDS: string (nullable = true)\n",
      " |-- ANTIBIOTICS: string (nullable = true)\n",
      " |-- ANESTHESIA: string (nullable = true)\n",
      " |-- DELIV_METHOD_RECODE_COMB: string (nullable = true)\n",
      " |-- ATTENDANT_BIRTH: string (nullable = true)\n",
      " |-- APGAR_5: integer (nullable = true)\n",
      " |-- APGAR_5_RECODE: string (nullable = true)\n",
      " |-- APGAR_10: integer (nullable = true)\n",
      " |-- APGAR_10_RECODE: string (nullable = true)\n",
      " |-- INFANT_SEX: string (nullable = true)\n",
      " |-- OBSTETRIC_GESTATION_WEEKS: integer (nullable = true)\n",
      " |-- INFANT_WEIGHT_GRAMS: integer (nullable = true)\n",
      " |-- INFANT_ASSIST_VENTI: string (nullable = true)\n",
      " |-- INFANT_ASSIST_VENTI_6HRS: string (nullable = true)\n",
      " |-- INFANT_NICU_ADMISSION: string (nullable = true)\n",
      " |-- INFANT_SURFACANT: string (nullable = true)\n",
      " |-- INFANT_ANTIBIOTICS: string (nullable = true)\n",
      " |-- INFANT_SEIZURES: string (nullable = true)\n",
      " |-- INFANT_NO_ABNORMALITIES: string (nullable = true)\n",
      " |-- INFANT_ANCEPHALY: string (nullable = true)\n",
      " |-- INFANT_MENINGOMYELOCELE: string (nullable = true)\n",
      " |-- INFANT_LIMB_REDUCTION: string (nullable = true)\n",
      " |-- INFANT_DOWN_SYNDROME: string (nullable = true)\n",
      " |-- INFANT_SUSPECTED_CHROMOSOMAL_DISORDER: string (nullable = true)\n",
      " |-- INFANT_NO_CONGENITAL_ANOMALIES_CHECKED: string (nullable = true)\n",
      " |-- INFANT_BREASTFED: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "births.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'INFANT_ALIVE_AT_REPORT', \n",
    "    'BIRTH_PLACE', \n",
    "    'MOTHER_AGE_YEARS', \n",
    "    'FATHER_COMBINED_AGE', \n",
    "    'CIG_BEFORE', \n",
    "    'CIG_1_TRI', \n",
    "    'CIG_2_TRI', \n",
    "    'CIG_3_TRI', \n",
    "    'MOTHER_HEIGHT_IN', \n",
    "    'MOTHER_PRE_WEIGHT', \n",
    "    'MOTHER_DELIVERY_WEIGHT', \n",
    "    'MOTHER_WEIGHT_GAIN', \n",
    "    'DIABETES_PRE', \n",
    "    'DIABETES_GEST', \n",
    "    'HYP_TENS_PRE', \n",
    "    'HYP_TENS_GEST', \n",
    "    'PREV_BIRTH_PRETERM'\n",
    "]\n",
    "\n",
    "births_trimmed = births.select(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "\n",
    "def recode(col, key):        \n",
    "    return recode_dictionary[key][col] \n",
    "\n",
    "def correct_cig(feat):\n",
    "    return func \\\n",
    "        .when(func.col(feat) != 99, func.col(feat))\\\n",
    "        .otherwise(0)\n",
    "\n",
    "rec_integer = func.udf(recode, typ.IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_transformed = births_trimmed \\\n",
    "    .withColumn('CIG_BEFORE', correct_cig('CIG_BEFORE'))\\\n",
    "    .withColumn('CIG_1_TRI', correct_cig('CIG_1_TRI'))\\\n",
    "    .withColumn('CIG_2_TRI', correct_cig('CIG_2_TRI'))\\\n",
    "    .withColumn('CIG_3_TRI', correct_cig('CIG_3_TRI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [(col.name, col.dataType) for col in births_trimmed.schema]\n",
    "\n",
    "YNU_cols = []\n",
    "\n",
    "for i, s in enumerate(cols):\n",
    "    if s[1] == typ.StringType():\n",
    "        dis = births.select(s[0]) \\\n",
    "            .distinct() \\\n",
    "            .rdd \\\n",
    "            .map(lambda row: row[0]) \\\n",
    "            .collect()\n",
    "\n",
    "        if 'Y' in dis:\n",
    "            YNU_cols.append(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "births.select([\n",
    "        'INFANT_NICU_ADMISSION', \n",
    "        rec_integer(\n",
    "            'INFANT_NICU_ADMISSION', func.lit('YNU')\n",
    "        ) \\\n",
    "        .alias('INFANT_NICU_ADMISSION_RECODE')]\n",
    "     ).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exprs_YNU = [\n",
    "    rec_integer(x, func.lit('YNU')).alias(x) \n",
    "    if x in YNU_cols \n",
    "    else x \n",
    "    for x in births_transformed.columns\n",
    "]\n",
    "\n",
    "births_transformed = births_transformed.select(exprs_YNU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_transformed.select(YNU_cols[-5:]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.mllib.stat as st\n",
    "import numpy as np\n",
    "\n",
    "numeric_cols = ['MOTHER_AGE_YEARS','FATHER_COMBINED_AGE',\n",
    "                'CIG_BEFORE','CIG_1_TRI','CIG_2_TRI','CIG_3_TRI',\n",
    "                'MOTHER_HEIGHT_IN','MOTHER_PRE_WEIGHT',\n",
    "                'MOTHER_DELIVERY_WEIGHT','MOTHER_WEIGHT_GAIN'\n",
    "               ]\n",
    "\n",
    "numeric_rdd = births_transformed\\\n",
    "                       .select(numeric_cols)\\\n",
    "                       .rdd \\\n",
    "                       .map(lambda row: [e for e in row])\n",
    "\n",
    "mllib_stats = st.Statistics.colStats(numeric_rdd)\n",
    "\n",
    "for col, m, v in zip(numeric_cols, \n",
    "                     mllib_stats.mean(), \n",
    "                     mllib_stats.variance()):\n",
    "    print('{0}: \\t{1:.2f} \\t {2:.2f}'.format(col, m, np.sqrt(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [e for e in births_transformed.columns \n",
    "                    if e not in numeric_cols]\n",
    "\n",
    "categorical_rdd = births_transformed\\\n",
    "                       .select(categorical_cols)\\\n",
    "                       .rdd \\\n",
    "                       .map(lambda row: [e for e in row])\n",
    "            \n",
    "for i, col in enumerate(categorical_cols):\n",
    "    agg = categorical_rdd \\\n",
    "        .groupBy(lambda row: row[i]) \\\n",
    "        .map(lambda row: (row[0], len(row[1])))\n",
    "        \n",
    "    print(col, sorted(agg.collect(), \n",
    "                      key=lambda el: el[1], \n",
    "                      reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = st.Statistics.corr(numeric_rdd)\n",
    "\n",
    "for i, el in enumerate(corrs > 0.5):\n",
    "    correlated = [\n",
    "        (numeric_cols[j], corrs[i][j]) \n",
    "        for j, e in enumerate(el) \n",
    "        if e == 1.0 and j != i]\n",
    "    \n",
    "    if len(correlated) > 0:\n",
    "        for e in correlated:\n",
    "            print('{0}-to-{1}: {2:.2f}' \\\n",
    "                  .format(numeric_cols[i], e[0], e[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = [\n",
    "    'INFANT_ALIVE_AT_REPORT', \n",
    "    'BIRTH_PLACE', \n",
    "    'MOTHER_AGE_YEARS', \n",
    "    'FATHER_COMBINED_AGE', \n",
    "    'CIG_1_TRI', \n",
    "    'MOTHER_HEIGHT_IN', \n",
    "    'MOTHER_PRE_WEIGHT', \n",
    "    'DIABETES_PRE', \n",
    "    'DIABETES_GEST', \n",
    "    'HYP_TENS_PRE', \n",
    "    'HYP_TENS_GEST', \n",
    "    'PREV_BIRTH_PRETERM'\n",
    "]\n",
    "births_transformed = births_transformed.select([e for e in features_to_keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.mllib.linalg as ln\n",
    "\n",
    "for cat in categorical_cols[1:]:\n",
    "    agg = births_transformed \\\n",
    "        .groupby('INFANT_ALIVE_AT_REPORT') \\\n",
    "        .pivot(cat) \\\n",
    "        .count()    \n",
    "\n",
    "    agg_rdd = agg \\\n",
    "        .rdd\\\n",
    "        .map(lambda row: (row[1:])) \\\n",
    "        .flatMap(lambda row: \n",
    "                 [0 if e == None else e for e in row]) \\\n",
    "        .collect()\n",
    "\n",
    "    row_length = len(agg.collect()[0]) - 1\n",
    "    agg = ln.Matrices.dense(row_length, 2, agg_rdd)\n",
    "    \n",
    "    test = st.Statistics.chiSqTest(agg)\n",
    "    print(cat, round(test.pValue, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x23539758748>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import folium\n",
    "\n",
    "chiba_map = folium.Map(location=[35.607451, 140.106340])\n",
    "\n",
    "chiba_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid API key provided.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-15ea6baa2802>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'api-key'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgmaps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgooglemaps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgmaps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse_geocode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m33.8674869\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m151.2069902\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\googlemaps\\client.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, key, client_id, client_secret, timeout, connect_timeout, read_timeout, retry_timeout, requests_kwargs, queries_per_second, channel, retry_over_query_limit)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"AIza\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid API key provided.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mchannel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid API key provided."
     ]
    }
   ],
   "source": [
    "import googlemaps\n",
    "\n",
    "key = 'api-key'\n",
    "gmaps = googlemaps.Client(key=key)\n",
    "\n",
    "results = gmaps.reverse_geocode((-33.8674869, 151.2069902))\n",
    "\n",
    "for result in results:\n",
    "    types = result['types']\n",
    "    print('types', types)\n",
    "    addr = result['formatted_address']\n",
    "    print('addr', addr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
