{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pysparkの自習まとめ  \n",
    "作成日2018/12/17 作成者　侯、石井さん"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、並列処理の定義  \n",
    "並列処理は何でしょうか    \n",
    "グーグルで「spark 入門」と検索  \n",
    "下記が、わかりやすい記事です。  \n",
    "\n",
    "https://qiita.com/Hiroki11x/items/4f5129094da4c91955bc  \n",
    "\n",
    "https://www.slideshare.net/hadoopxnttdata/apache-spark-for-beginners-ntt-data-saruta-spark-conference-japan-2016  \n",
    "\n",
    "http://www.atmarkit.co.jp/ait/articles/1608/24/news014.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、RDDの定義（しっかり理解したほうがいいと思います。）  \n",
    "「SPARK RDDとは」と検索  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、環境構築  \n",
    "pysparkは、python言語でsparkを操作するAPIです。  \n",
    "使えるまでの環境構築はややこしいものです。  \n",
    "この記事は一番わかりやすいと思います。  \n",
    "https://changhsinlee.com/install-pyspark-windows-jupyter/  \n",
    "（注意：sparkのバージョンについて、最新バージョン(2.4.0)をインストールすると、エラーが出ますので(12月上旬時点で)、2.3.xにしましょう ）  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4、RDD操作、データフレーム操作  \n",
    "データフレーム操作がメイン（pandasとの比較とか）  \n",
    "pyspark入門  \n",
    "https://www.slideshare.net/tatsuyaatsumi/pythonapache-spark-at-pycon2016  \n",
    "\n",
    "RDDとDF操作の基本、RDDとDFの区別    \n",
    "https://techblog.recruitjobs.net/development/basic_data_types_of_spark  \n",
    "\n",
    "pysparkによるDF操作  \n",
    "https://blog.amedama.jp/entry/2018/03/03/173257  \n",
    "\n",
    "DF操作  \n",
    "https://fisproject.jp/2018/04/methods-of-the-pyspark-sql-dataframe-class/  \n",
    "\n",
    "公式ドキュメントによると、機械学習をする際に、データフレーム(RDDではなく)による機械学習がメインなので、上記リンクで、データフレームの操作になれるのに十分だと思います。 \n",
    "\n",
    "実際動かしたいときは、irisとかのデータセットで動かすのがおすすめです。  \n",
    "例：  \n",
    "https://github.com/kou-kaku-albert/self_learning/blob/master/spark/1203_pyspark%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E3%83%BBiris%E3%81%A7%E5%85%A5%E9%96%80.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5、pysparkによるML  \n",
    "公式ドキュメント(日本語)  \n",
    "http://mogile.web.fc2.com/spark/spark200/ml-guide.html  \n",
    "公式のドキュメントが一番おすすめ。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6、実際の課題をやってみたほうがいいと思います。  \n",
    "(pysparkの使い方になれるために、リンクに参照しながら、1つを実装します。(1日～2日で終わると思います)  \n",
    "また、もう一つのプロジェクトを、例えば銀行契約予測の場合はkaggleのリンクだけ与え、何も参照せずに0から作るのがおすすめです。)\n",
    "\n",
    "ボストン住宅価格予測  \n",
    "https://towardsdatascience.com/building-a-linear-regression-with-pyspark-and-mllib-d065c3ba246a  \n",
    "\n",
    "タイタニック生存予測  \n",
    "http://localhost:8888/notebooks/Desktop/00_self_learning/spark/1204_Titanic_survival_by_PySpark.ipynb  \n",
    "\n",
    "銀行契約予測  \n",
    "https://www.kaggle.com/janiobachmann/bank-marketing-dataset  \n",
    "\n",
    "https://towardsdatascience.com/machine-learning-with-pyspark-and-mllib-solving-a-binary-classification-problem-96396065d2aa  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考資料  \n",
    "『learning-pyspark』という本は体系的にpysparkについて書いてあります。  \n",
    "ネットで検索したら無料版はあります。  \n",
    "ただ、英語版しかなくて、少し読みにくいです。  \n",
    "コード：\n",
    "https://github.com/drabastomek/learningPySpark  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pysparkのチートシート  \n",
    "https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
