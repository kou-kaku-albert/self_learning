{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本的なものは全部乗っているんで、辞書ともいえるかと思います"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ構造の確認  \n",
    "射影・抽出  \n",
    "要約統計量  \n",
    "結合  \n",
    "グループ化・集約  \n",
    "欠測値の確認・削除・補完  \n",
    "重複値の削除  \n",
    "置換・ソート  \n",
    "サンプリング  \n",
    "データ形式の変換  \n",
    "日時の変換  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('for_data_flame').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x0000016F5A66DF28>\n"
     ]
    }
   ],
   "source": [
    "print(spark)\n",
    "df = spark.createDataFrame(\n",
    " [(1, 144.5, 5.9, 33, 'M'), (2, 167.2, 5.4, 45, 'M'), (3, 124.1, 5.2, 23, 'F'),\n",
    "(4, 144.5, 5.9, 33, 'M'), (5, 133.2, 5.7, 54, 'F'), (3, 124.1, 5.2, 23, 'F'),\n",
    " (6, 149.3, None, 54, 'M'),],\n",
    " ['id', 'weight', 'height', 'age', 'gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "射影・抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|gender|\n",
      "+---+------+\n",
      "|  1|     M|\n",
      "|  2|     M|\n",
      "|  3|     F|\n",
      "|  4|     M|\n",
      "|  5|     F|\n",
      "|  3|     F|\n",
      "|  6|     M|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('id','gender').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  6| 149.3|  null| 54|     M|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.weight > 145.0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  6| 149.3|  null| 54|     M|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df.weight > 145.0) | (df.gender == 'M')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.filter(~(col(\"weight\") > 145.0) & (col(\"gender\") == 'M')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+\n",
      "| id|weight|height|gender|\n",
      "+---+------+------+------+\n",
      "|  1| 144.5|   5.9|     M|\n",
      "|  2| 167.2|   5.4|     M|\n",
      "|  3| 124.1|   5.2|     F|\n",
      "|  4| 144.5|   5.9|     M|\n",
      "|  5| 133.2|   5.7|     F|\n",
      "|  3| 124.1|   5.2|     F|\n",
      "|  6| 149.3|  null|     M|\n",
      "+---+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.drop(\"age\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要約統計量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "describe、summaryは、知っているので、省く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.18954238554989092"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#相関係数\n",
    "df.corr(\"weight\", \"height\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.160714285714284"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#共分散\n",
    "df.cov(\"weight\", \"height\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.createDataFrame([(1, 'Tokyo',), (2, 'Kyoto',), ], ['id', 'from'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+------+------+---+------+\n",
      "| id| from| id|weight|height|age|gender|\n",
      "+---+-----+---+------+------+---+------+\n",
      "|  1|Tokyo|  1| 144.5|   5.9| 33|     M|\n",
      "|  2|Kyoto|  2| 167.2|   5.4| 45|     M|\n",
      "+---+-----+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#join\n",
    "df2.join(df,df2.id == df.id,'left').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+\n",
      "|age|gender| from|\n",
      "+---+------+-----+\n",
      "| 33|     M|Tokyo|\n",
      "| 33|     M|Kyoto|\n",
      "| 45|     M|Tokyo|\n",
      "| 23|     F|Tokyo|\n",
      "| 45|     M|Kyoto|\n",
      "| 23|     F|Kyoto|\n",
      "| 33|     M|Tokyo|\n",
      "| 54|     F|Tokyo|\n",
      "| 33|     M|Kyoto|\n",
      "| 54|     F|Kyoto|\n",
      "| 23|     F|Tokyo|\n",
      "| 54|     M|Tokyo|\n",
      "| 23|     F|Kyoto|\n",
      "| 54|     M|Kyoto|\n",
      "+---+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#cross join\n",
    "df.crossJoin(df2.select(\"from\")).select(\"age\", \"gender\", \"from\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "?????? ジョインはとても遅いですね"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " df3 = spark.createDataFrame([(7, 122.7, 5.1, 36, 'F')],\n",
    " ['id', 'weight', 'height', 'age', 'gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  6| 149.3|  null| 54|     M|\n",
      "|  7| 122.7|   5.1| 36|     F|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.union(df3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  6| 149.3|  null| 54|     M|\n",
      "|  7| 122.7|   5.1| 36|     F|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('df')\n",
    "df3.registerTempTable('df3')\n",
    "spark.sql('''select * from df\n",
    "union all \n",
    "select * from df3\n",
    "'''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg(height)=5.550000000000001)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"height\").groupBy().mean().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+------------------+-----------------+------------------+\n",
      "|gender|           avg(id)|       avg(weight)|      avg(height)|          avg(age)|\n",
      "+------+------------------+------------------+-----------------+------------------+\n",
      "|     F|3.6666666666666665|127.13333333333333|5.366666666666667|33.333333333333336|\n",
      "|     M|              3.25|           151.375|5.733333333333334|             41.25|\n",
      "+------+------------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('gender').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg(age)=37.857142857142854)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.agg({\"age\": \"mean\"}).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  6| 149.3|  null| 54|     M|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"height\").isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欠損値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  6| 149.3|  null| 54|     M|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"height\").isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " df.filter(col(\"height\").isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  6| 149.3|   5.6| 54|     M|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "height_mean = round(df.select(\"height\").groupBy().avg().head()[0], 1)\n",
    "df.fillna(height_mean).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "置換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  1| 144.5|   5.9| 33|   man|\n",
      "|  2| 167.2|   5.4| 45|   man|\n",
      "|  3| 124.1|   5.2| 23| women|\n",
      "|  4| 144.5|   5.9| 33|   man|\n",
      "|  5| 133.2|   5.7| 54| women|\n",
      "|  3| 124.1|   5.2| 23| women|\n",
      "|  6| 149.3|  null| 54|   man|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.replace(['M', 'F'], ['man', 'women'], 'gender').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  6| 149.3|  null| 54|     M|\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "df.orderBy(desc('age')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  6| 149.3|  null| 54|     M|\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(df.age.desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, unix_timestamp, to_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = spark.createDataFrame([(1, \"2018-04-29 16:09:16\"), (2, \"2018-04-29 18:01:32\")], (\"id\", \"dt_str\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+----------+\n",
      "| id|             dt_str|        ts|\n",
      "+---+-------------------+----------+\n",
      "|  1|2018-04-29 16:09:16|1524985756|\n",
      "|  2|2018-04-29 18:01:32|1524992492|\n",
      "+---+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " df_ts.withColumn(\"ts\", unix_timestamp(\"dt_str\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1, dt_str='2018-04-29 16:09:16', dt=datetime.datetime(2018, 4, 29, 16, 9, 16)),\n",
       " Row(id=2, dt_str='2018-04-29 18:01:32', dt=datetime.datetime(2018, 4, 29, 18, 1, 32))]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ts.withColumn(\"dt\", to_timestamp(\"dt_str\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour = udf(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------------------+----+\n",
      "| id|             dt_str|                 dt|hour|\n",
      "+---+-------------------+-------------------+----+\n",
      "|  1|2018-04-29 16:09:16|2018-04-29 16:09:16|  16|\n",
      "|  2|2018-04-29 18:01:32|2018-04-29 18:01:32|  18|\n",
      "+---+-------------------+-------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ts.withColumn(\"dt\", to_timestamp(\"dt_str\")).withColumn('hour', hour(col('dt'))).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
